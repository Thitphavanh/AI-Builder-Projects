{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image classification**\n",
    "\n",
    "\n",
    "จากบทเรียนที่น้องๆได้ลองเรียนมานั้น จะเห็นว่า Deep learning สามารถนำไปใช้งานได้หลากหลายวิธีมากๆ หนึ่งในงานที่ใช้กันแพร่หลายมากคือ Image classification\n",
    "\n",
    "โดยในบทเรียนแรกนี้เราจะมาลองทำ Image classification กันโดยใช้ library ที่ชื่อว่า Pytorch และ Pytorch Lightning\n",
    "\n",
    "โดย Dataset ที่เราจะเลือกใช้ในวันนี้จะใช้ชุดข้อมูลจาก Kaggle https://www.kaggle.com/c/dog-breed-identification\n",
    "\n",
    "Reference:\n",
    "- https://github.com/udacity/deep-learning-v2-pytorch\n",
    "- https://albumentations.ai/docs/getting_started/image_augmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! นำหน้าใน Notebook แปลว่าให้รันใน Terminal\n",
    "!pip install kaggle\n",
    "!kaggle competitions download -c dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทำการ unzip .zip ไฟล์ที่ดาวน์โหลดมา\n",
    "!unzip dog-breed-identification.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **แบ่งชุดข้อมูลเป็น training, validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all image paths\n",
    "img_df = pd.DataFrame(glob(\"data/train/*.jpg\"), columns=[\"path\"])\n",
    "img_df[\"id\"] = img_df.path.map(lambda x: op.basename(x).replace(\".jpg\", \"\"))\n",
    "\n",
    "# read label data\n",
    "label_df = pd.read_csv(\"data/labels.csv\")\n",
    "train_df = img_df.merge(label_df, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train_df, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of training set = {}, validation set = {}\".format(len(train_df), len(validation_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/dogdata/\"\n",
    "for df, f in zip([train_df, validation_df], [\"train\", \"validation\"]):\n",
    "    for _, r in df.iterrows():\n",
    "        # create subfolder if it doesn't exist\n",
    "        d = op.join(root_dir, f, r.breed)\n",
    "        if not op.exists(d):\n",
    "            os.makedirs(d)\n",
    "        shutil.copy(r.path, op.join(root_dir, f, r.breed, f\"{r.id}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image classification ด้วย Pytorch ล้วนๆ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.Resize(256)\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.TrivialAugmentWide(),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\"data/dogdata/train/\", transform=train_transform)\n",
    "val_data = datasets.ImageFolder(\"data/dogdata/validation/\", transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_loader.dataset)\n",
    "n_val = len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่างการโหลดออกมา 1 batch\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 = batch size, 3 = depth, 224 = height, 224 = width\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2_class = {v: k for k, v in train_data.class_to_idx.items()}\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for i in range(10):\n",
    "    image = np.transpose(images.cpu()[i])\n",
    "    label = idx2_class[labels.cpu().tolist()[i]]\n",
    "    ax = fig.add_subplot(2, 8, i + 1, xticks=[], yticks=[])\n",
    "    plt.imshow(image)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง pretrained model\n",
    "model = models.resnet34(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปลี่ยนพารามิเตอร์ใน fc ให้สำหรับทำนายพันธุ์หมาแทน, เช็คก่อนเสมอว่าโมเดลหน้าตาเป็นอย่างไร\n",
    "model.fc = nn.Linear(in_features=512, out_features=len(train_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง loss, optimizer\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เช็คว่ามี GPU ที่สามารถใช้ได้มั้ย ถ้าใช้ได้นำโมเดลเข้าไปอยู่ใน GPU\n",
    "gpu = torch.cuda.is_available()\n",
    "print(gpu)\n",
    "if gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "for epoch in range(n_epochs):\n",
    "    # ช่วง train\n",
    "    model.train()\n",
    "    train_loss, val_loss = 0, 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        if gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(images) # คำนวณหา output (pred) จาก โมเดลที่มีอยู่\n",
    "        loss = cross_entropy(pred, labels)\n",
    "        loss.backward() # คำนวณ gradient จาก loss ที่ได้\n",
    "        optimizer.step() # อัพเดทพารามิเตอร์ของโมเดล\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # ช่วง validate\n",
    "    model.eval() # เซ็ตเป็น evaluation mode\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        if gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        pred = model(images)\n",
    "        loss = cross_entropy(pred, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "    print(\"Training loss = {}, Validation loss = {}\".format(train_loss / n_train, val_loss / n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# คำนวณหา classification report สำหรับ validation set\n",
    "y_pred, y_true = [], []\n",
    "model.eval() # เซ็ตเป็น evaluation mode\n",
    "for images, labels in tqdm(val_loader):\n",
    "    if gpu:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "    pred = model(images)\n",
    "    yp = pred.argmax(dim=1).tolist()\n",
    "    yt = labels.tolist()\n",
    "    y_pred.extend(yp)\n",
    "    y_true.extend(yt)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on validation set = {}\".format(\n",
    "    accuracy_score(y_true, y_pred))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Recall F1-Score\",\n",
    "      precision_recall_fscore_support(y_true, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ทดลอง Forward pass**\n",
    "\n",
    "เราสามารถลองดูได้ว่า forward pass ของเราทำงานได้ปกติมั้ย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "backbone = models.resnet34(pretrained=True)\n",
    "backbone.fc = torch.nn.Linear(backbone.fc.in_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape, y.shape # batch size, number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_loss = nn.CrossEntropyLoss()\n",
    "entropy_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image classification ด้วย Pytorch Lightning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.TrivialAugmentWide(),\n",
    "    T.RandomResizedCrop((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\"data/dogdata/train/\", transform=train_transform)\n",
    "val_data = datasets.ImageFolder(\"data/dogdata/validation/\", transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data.classes\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogResNet(pl.LightningModule):\n",
    "    def __init__(self, n_classes=120):\n",
    "        super(DogResNet, self).__init__()\n",
    "        \n",
    "        # จำนวนของพันธุ์น้องหมา (120)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # ใช้สถาปัตยกรรม resnet34; เปลี่ยน layer สุดท้าย\n",
    "        self.backbone = models.resnet34(pretrained=True)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        # เปลี่ยน fc layer เป็น output ขนาด 120\n",
    "        self.backbone.fc = torch.nn.Linear(self.backbone.fc.in_features, n_classes)\n",
    "        \n",
    "        self.entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        preds = self.backbone(x)\n",
    "        return pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = self.entropy_loss(logits, y)\n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.accuracy(y_pred, y))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = self.entropy_loss(logits, y)\n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.accuracy(y_pred, y))\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DogResNet(n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "   dirpath=\"./checkpoints/dogbreed/\",\n",
    "   filename=\"resnet18--{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}\",\n",
    "   save_top_k=1,\n",
    "   verbose=True,\n",
    "   monitor=\"val_loss\",\n",
    "   mode=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, gpus=1, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
